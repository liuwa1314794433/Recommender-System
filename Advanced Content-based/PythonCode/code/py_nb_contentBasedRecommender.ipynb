{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMM7380 Recommender Systems for Digital Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages using pip package manager in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install nltk\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing our dataset\n",
    "\n",
    "The dataset includes the descriptions of famous movies from [imdb.com](https://www.imdb.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../data/' + 'imdb_movie_description.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Take a glance at the head \n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape # How many?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `id` column is a duplicated index, can be dropped safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.drop(columns=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing pipeline\n",
    "\n",
    "Import the Natural Language toolkit (`nltk`) library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to take care of text preprocessing (cleaning, tokenizing and stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Remove punctuation\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # Remove Stop Words (all lowercase in corpora)\n",
    "    stop_words = set(nltk.corpus.stopwords.words('english')) \n",
    "    filteredTokens = [w for w in tokens if not w.lower() in stop_words]\n",
    "    \n",
    "    # Create stemmed tokens using the Porter stemmer\n",
    "    # Also convert to lowercase\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    stems = []\n",
    "    for item in filteredTokens:\n",
    "        stems.append(stemmer.stem(item))\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select a part of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedMovies = movies.head(500)\n",
    "#selectedMovies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenized descriptions of the movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDesc = []\n",
    "for index, movie in movies.iterrows():\n",
    "    tokenDesc.append(tokenize(movie['description']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenDesc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "\n",
    "1. Create a function `add_genre` that will add the movie genres to tokens in the form $<genreId>genre$ (e.g. `18genre`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling using LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to generate a corpora for training our model. \n",
    "We will use `gensim` library to create\n",
    "- a dictionary \n",
    "- and a corpora of bags of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First generate a dictionary from our token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenDesc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, generate a corpus containing a Bag of Words for each description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in tokenDesc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate an LDA model\n",
    "\n",
    "The number of topics (10 in our example) is one of the many parameters that can be tuned.\n",
    "We are going to use the standard values for the other parameters, for a full list please refer to the [gensim LDA manual page](https://radimrehurek.com/gensim/models/ldamodel.html).\n",
    "\n",
    "Note: changing parameters when your recommender is \"live\" require to update all the previously computed topics.\n",
    "\n",
    "Performance wise, training this model can be time and memory consuming. Since it is model based, it's suggested to persist the model to disk once you find a good combination of number of topics (and eventually of other parameters). You can do it by using `lda_model.save(filename)` and load it by using `lda_model.load(filename)` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics = 10\n",
    "\n",
    "lda_model = models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                     id2word=dictionary,\n",
    "                                     num_topics=n_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which topics have been discovered. Can be confusing to analyse.\n",
    "\n",
    "Each tuple start with topic number and a list of terms and their probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics are a machine interpretation of text. This doesn't mean that they are human-interpretable.\n",
    "\n",
    "Some sanity check is needed, to see if it can \"make sense\" (e.g. doesn't categorise Terminator as Romance... even if...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic distribution of a document\n",
    "\n",
    "Let's input a new document to our model, to extract its classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get from dataset\n",
    "newdoc = movies['description'].iloc[1001]\n",
    "\n",
    "# Tokenize the text\n",
    "tokensNewdoc = tokenize(newdoc)\n",
    "print(tokensNewdoc)\n",
    "\n",
    "# Convert to Bag of Words\n",
    "newCorpus = dictionary.doc2bow(tokensNewdoc)\n",
    "\n",
    "# Extract the topic of the new document with the model\n",
    "sim = lda_model[newCorpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a list of similarities with topics in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content similarity using LDA topics\n",
    "\n",
    "Compute cosine similarity between the documents. The result is a square similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexLDA = similarities.MatrixSimilarity(lda_model[corpus])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in indexLDA:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there are some differences with the cosine similarity between the items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexCos = similarities.MatrixSimilarity(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in indexCos:\n",
    "    print(item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending similar items\n",
    "\n",
    "Let's recommend some content to our user.\n",
    "\n",
    "To simplify the discussion, we skip the selection of the best movies. We already selected somewhere else and saved to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestMoviesIDs = [11, 181808, 140607, 284053, 73338, 424, 27205, 354912, 332562]\n",
    "\n",
    "bestMovies = movies[movies['movie_id'].isin(bestMoviesIDs)]\n",
    "print(bestMovies['title'])\n",
    "print(bestMovies.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similar items\n",
    "\n",
    "First define a function for returning similarity matrix rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_item_by_id(simMatrix, itemId):\n",
    "    '''\n",
    "        Input: gensim similaritymatrix and itemId\n",
    "        Returns the item similarity if found\n",
    "        Returns false otherwise\n",
    "    '''\n",
    "    \n",
    "    count = 0\n",
    "    search = itemId\n",
    "    for item in simMatrix:\n",
    "        if count == search:\n",
    "            itemFound = item\n",
    "            break\n",
    "        count += 1\n",
    "        \n",
    "    itemFound == False\n",
    "    \n",
    "    return itemFound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define a function for recommending items basing on content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_rec_items(df, itemList, minSim, maxSim, maxItems):\n",
    "    \n",
    "    # Create list of indexes\n",
    "    count = 0\n",
    "    indexList = []\n",
    "    for item in itemList:\n",
    "        if item < maxSim:\n",
    "            if item > minSim:\n",
    "                indexList.append(count)\n",
    "        count +=1\n",
    "    \n",
    "    items = df.iloc[indexList]\n",
    "    \n",
    "    if maxItems > 0:\n",
    "        items = items.head(maxItems) # Can be optimised?\n",
    "        \n",
    "    #print(items['title'])\n",
    "    return items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the recommendations for our user, basing on the description of movies he liked compared to the descriptions of other items.\n",
    "\n",
    "Use some parameters to filter the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSim, maxSim, maxItems = 0.1, 1, 3\n",
    "sim = indexLDA\n",
    "\n",
    "for item in bestMovies.index:\n",
    "    similarItems = search_item_by_id(sim, item)\n",
    "    #print(similarItems)\n",
    "    recItems = content_rec_items(movies, similarItems, minSim, maxSim, maxItems)\n",
    "    print(recItems['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the same using cosine similarity between the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minSim, maxSim, maxItems = 0.1, 1, 3\n",
    "sim = indexCos\n",
    "\n",
    "for item in bestMovies.index:\n",
    "    similarItems = search_item_by_id(sim, item)\n",
    "    #print(similarItems)\n",
    "    recItems = content_rec_items(movies, similarItems, minSim, maxSim, maxItems)\n",
    "    print(recItems['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. When using the LDA similarity matrix, print the starting movie name before the recommendation (eventually \"cleanup\" the list print)\n",
    "1. Tune the recommendation parameters to see if you can achieve better results than cosine similarity\n",
    "1. Tune the number of topics extracted by the LDA model, can you find a number of topics that makes more sense when evaluating the recommendations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Course Instructor: Dr. Paolo Mengoni (Visiting Scholar, School of Communication, Hong Kong Baptist University) \n",
    "  - pmengoni@hkbu.edu.hk\n",
    "\n",
    "- The codes in this notebook take insipiration from various sources. All codes are for educational purposes only and released under the CC1.0. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
