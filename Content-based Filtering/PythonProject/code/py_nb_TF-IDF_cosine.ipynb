{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMM7380 Recommender Systems for Digital Media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NetworkX, Matplotlib, Pandas, Numpy using pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install pandas\n",
    "!{sys.executable} -m pip install numpy\n",
    "!{sys.executable} -m pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import time\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine Similarity\n",
    "def cosine_similarity(x, y):\n",
    "    x_sqrt = np.sqrt(np.dot(x, x))\n",
    "    y_sqrt = np.sqrt(np.dot(y, y))\n",
    "    if y_sqrt != 0:     \n",
    "        return (np.dot(x,y.T) / (x_sqrt * y_sqrt))\n",
    "    elif y_sqrt == 0:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test cosine_similarity\n",
    "print (cosine_similarity(np.array([1,2,3]), np.array([1,2,3])))\n",
    "print (cosine_similarity(np.array([3,4,5]), np.array([1,3,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Inverted Index & Document Count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function to remove numbers, punctuation and digits. Fixes some identified problems in data (such as cnn without spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(texts):\n",
    "    # input : string that needs to clean all number and signs\n",
    "\n",
    "    texts = re.sub('cnn',' cnn ', texts) # Needed for some news not correctl\n",
    "    texts = re.sub('\\'', ' ', texts)\n",
    "    texts = ''.join(c for c in texts if c not in string.punctuation)\n",
    "    texts = ''.join([c for c in texts if not c.isdigit()])\n",
    "    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dictionaries:\n",
    "- doc2vocab: includes for each document a list of tuples containing (term: number of occurrences)\n",
    "-- `Doc 0 : (term1: num 1), (term2 : num 2), (term3 : num 3), ...`\n",
    "- vocab2doc: includes for each word in which document it can be found\n",
    "-- `word : [text_num1, text_num2, ... ]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vocab  = dict()\n",
    "vocab2doc  = dict()\n",
    "\n",
    "#We consider 60 documents in our collection\n",
    "for i in range(0,60):\n",
    "    doc2vocab[i] = dict()\n",
    "\n",
    "    with open('../data/docs/%d.txt' % i, 'r', encoding=\"utf-8\") as doc:\n",
    "        read_string = doc.read()                       # get sentence as read function\n",
    "        read_string = read_string.lower()              # sentence lower\n",
    "        read_string = clean_str(read_string)           # clean all punctuation and number\n",
    "        \n",
    "        tokens = nltk.word_tokenize(read_string)       # get tokens of sentence\n",
    "        stop = set(stopwords.words('english'))\n",
    "        tokens = [j for j in tokens if j not in stop] # get rid of stopwords at token\n",
    "        \n",
    "        ### get shape of {doc : {word1 : word1_num, word2 : word2_num, .... }}\n",
    "        for words in tokens:\n",
    "            # make document and vocab pair dictionary\n",
    "            if words in doc2vocab[i]:\n",
    "                doc2vocab[i][words] += 1\n",
    "                \n",
    "            else:\n",
    "                doc2vocab[i][words] = 1\n",
    "            \n",
    "            # make inverted index, {word : [doc1, doc3, ... ]}\n",
    "            text_str = str(i) + '.txt'\n",
    "            if words in vocab2doc:\n",
    "                if text_str not in vocab2doc[words]:\n",
    "                    vocab2doc[words].append(text_str)\n",
    "                    \n",
    "            else:\n",
    "                vocab2doc[words] = list()\n",
    "                vocab2doc[words].append(text_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index: president, obama list posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted Index Posting Lists Result\n",
    "print ('president : ', vocab2doc['president'])\n",
    "print ('obama : ', vocab2doc['obama'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Term Frequency and Inverted Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_pd = pd.DataFrame.from_dict(doc2vocab, orient='index')\n",
    "term_pd = term_pd.fillna(0)\n",
    "term_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Document TF-IDF (on single term) and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def doc_tf_idf(dataframe, query):\n",
    "    \n",
    "    # query tf-idf\n",
    "    _, width = dataframe.shape\n",
    "    final = list()\n",
    "    \n",
    "    # document tf-idf \n",
    "    new_tf = dataframe\n",
    "    doc_term_value = dataframe[dataframe > 0].count().values # get array of number that document has that term\n",
    "    doc_frequency = np.log(60 / (doc_term_value + 1))\n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(len(dataframe)):\n",
    "        results = np.zeros(width)\n",
    "        one_row = dataframe.loc[i]\n",
    "        row_value = one_row.values\n",
    "        row_index = one_row.index\n",
    "        \n",
    "        for j,term in enumerate(row_index):\n",
    "            if row_value[j] > 0:\n",
    "                term_frequency = np.log(row_value[j] + 1)\n",
    "                new_tf.iloc[i,j] = term_frequency * doc_frequency[j]\n",
    "                    \n",
    "            elif row_value[j] == 0:\n",
    "                term_frequency = 0\n",
    "                new_tf.iloc[i,j] = 0\n",
    "                \n",
    "            if term in query:\n",
    "                new_column = dataframe[[term]]\n",
    "                new_col_value = new_column[new_column > 0].count().values\n",
    "                results[j] = term_frequency * (np.log(60 / (new_col_value[0]+1)))\n",
    "        \n",
    "        final.append((i, cosine_similarity(new_tf.loc[i].values, results)))\n",
    "    \n",
    "        if i % 10 == 0:\n",
    "            print ('step : %d, time : %f' % (i, time.time()-start))\n",
    "            \n",
    "    return new_tf, final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get query and Compute Document TF-IDF weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a query\n",
    "query = ['president', 'obama']\n",
    "\n",
    "# Tokenize the query\n",
    "query_token = nltk.word_tokenize(query[0])\n",
    "\n",
    "# Compute TF-IDF\n",
    "term_doc_matrix, query_tf_idf = doc_tf_idf(term_pd, query_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF: president, obama term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print (term_doc_matrix[['president']])\n",
    "print (term_doc_matrix[['obama']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine-Similarity: president obama Top 5 Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# (Document number, Cosine-Similarity between query and document)\n",
    "score = sorted(query_tf_idf, key = lambda x : x[1], reverse=True)\n",
    "score[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Course Instructor: Dr. Paolo Mengoni (Visiting Scholar, School of Communication, Hong Kong Baptist University) \n",
    "  - pmengoni@hkbu.edu.hk\n",
    "\n",
    "- The codes in this notebook take insipiration from various sources. Thanks to [minstar](https://github.com/minstar/TF-IDF)\n",
    "- All codes are for educational purposes only and released under the CC1.0. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
